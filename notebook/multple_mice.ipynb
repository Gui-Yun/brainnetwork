{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, ttest_rel\n",
    "from brainnetwork import load_data, preprocess_data, preprocess_spike_data\n",
    "from brainnetwork import classify_by_timepoints, FI_by_timepoints_v2, FI_by_neuron_count\n",
    "from brainnetwork import construct_correlation_network, compute_network_metrics_by_class\n",
    "from brainnetwork.visualization import *\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/beegfs_hdd/data/nfs_share/users/guiyun/nishome/Micedata/\"\n",
    "data_path =  [\"M21_1107\", \"M71_1024\",\"M77_1031\",\"M78_1017\",\"M91_1017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = {1: \"Convergent\", 2: \"Divergent\", 3: \"Random\"}\n",
    "CLASS_COLORS = {1: \"#1F77B4\", 2: \"#D55E00\", 3: \"#009E73\"}\n",
    "CLASS_PAIRS = [(1, 2), (1, 3), (2, 3)]\n",
    "NETWORK_METRICS = [\n",
    "    \"n_edges\",\n",
    "    \"density\",\n",
    "    \"mean_degree\",\n",
    "    \"largest_component\",\n",
    "    \"avg_clustering\",\n",
    "    \"global_efficiency\",\n",
    "    \"local_efficiency\",\n",
    "    \"transitivity\",\n",
    "    \"efficiency\",\n",
    "    \"modularity\",\n",
    "    \"edge_weight_mean\",\n",
    "    \"edge_weight_abs_mean\",\n",
    "]\n",
    "GRAPH_CONFIGS = {\n",
    "    \"density\": {\n",
    "        \"label\": \"Top 5% edge density\",\n",
    "        \"threshold\": None,\n",
    "        \"top_k\": 0.05,\n",
    "        \"weighted\": False,\n",
    "        \"absolute\": False,\n",
    "    },\n",
    "    \"threshold\": {\n",
    "        \"label\": \"Correlation >= 0.5\",\n",
    "        \"threshold\": 0.5,\n",
    "        \"top_k\": None,\n",
    "        \"weighted\": False,\n",
    "        \"absolute\": False,\n",
    "    },\n",
    "}\n",
    "STRATEGY_COLORS = {\n",
    "    \"density\": \"#4C5B5C\",\n",
    "    \"threshold\": \"#E07A5F\",\n",
    "}\n",
    "ACCURACY_COLORS = {\"observed\": \"#22223B\", \"shuffled\": \"#B8B8B8\"}\n",
    "\n",
    "\n",
    "def process_mouse(mouse_id):\n",
    "    data_dir = os.path.join(base_dir, mouse_id)\n",
    "    print(f\"Processing {mouse_id} -> {data_dir}\")\n",
    "\n",
    "    neuron_data, neuron_pos, start_edges, stimulus_data = load_data(data_dir)\n",
    "    segments_spi, labels_spi, neuron_pos_spi = preprocess_spike_data(\n",
    "        neuron_data,\n",
    "        neuron_pos,\n",
    "        start_edges,\n",
    "        stimulus_data,\n",
    "    )\n",
    "\n",
    "    neuron_data_flo, neuron_pos_flo, start_edges_flo, stimulus_data_flo = load_data(\n",
    "        data_dir,\n",
    "        data_type=\"fluorescence\",\n",
    "    )\n",
    "    segments_flo, labels_flo, neuron_pos_flo = preprocess_data(\n",
    "        neuron_data_flo,\n",
    "        neuron_pos_flo,\n",
    "        start_edges_flo,\n",
    "        stimulus_data_flo,\n",
    "    )\n",
    "\n",
    "    accuracies, time_points_acc, accuracy_std, n_folds = classify_by_timepoints(\n",
    "        segments_flo,\n",
    "        labels_flo,\n",
    "    )\n",
    "    labels_shuffled = np.random.permutation(labels_flo)\n",
    "    accuracies_shuffled, time_points_shu, accuracy_std_shu, _ = classify_by_timepoints(\n",
    "        segments_flo,\n",
    "        labels_shuffled,\n",
    "    )\n",
    "    if not np.allclose(time_points_acc, time_points_shu):\n",
    "        raise ValueError(\"Classification time axes do not match for shuffled baseline.\")\n",
    "\n",
    "    fisher_mv, time_points_fi = FI_by_timepoints_v2(\n",
    "        segments_flo,\n",
    "        labels_flo,\n",
    "        mode=\"multivariate\",\n",
    "        reduction=None,\n",
    "    )\n",
    "    fisher_uv, time_points_fi_uv = FI_by_timepoints_v2(\n",
    "        segments_flo,\n",
    "        labels_flo,\n",
    "        mode=\"univariate\",\n",
    "        reduction=\"mean\",\n",
    "    )\n",
    "    if not np.allclose(time_points_fi, time_points_fi_uv):\n",
    "        raise ValueError(\"Time axes do not match between FI variants.\")\n",
    "\n",
    "    neuron_counts, fi_values = FI_by_neuron_count(segments_flo, labels_flo)\n",
    "\n",
    "    network_results = compute_networks_with_strategies(\n",
    "        segments_spi,\n",
    "        labels_spi,\n",
    "        neuron_pos_spi,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"mouse_id\": mouse_id,\n",
    "        \"fisher_mv\": fisher_mv,\n",
    "        \"fisher_uv\": fisher_uv,\n",
    "        \"time_points\": time_points_fi,\n",
    "        \"network_results\": network_results,\n",
    "        \"accuracy_curve\": {\n",
    "            \"mouse_id\": mouse_id,\n",
    "            \"time_axis\": time_points_acc,\n",
    "            \"accuracies\": accuracies,\n",
    "            \"accuracy_std\": accuracy_std,\n",
    "            \"shuffle\": accuracies_shuffled,\n",
    "            \"shuffle_std\": accuracy_std_shu,\n",
    "            \"n_folds\": n_folds,\n",
    "        },\n",
    "        \"fi_by_neuron\": {\n",
    "            \"counts\": neuron_counts,\n",
    "            \"values\": fi_values,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_networks_with_strategies(segments, labels, neuron_pos):\n",
    "    results = {}\n",
    "    for strategy_name, cfg in GRAPH_CONFIGS.items():\n",
    "        strategy_result = {}\n",
    "        for cls in np.unique(labels):\n",
    "            corr_matrix, graph, summary = construct_correlation_network(\n",
    "                segments,\n",
    "                labels=labels,\n",
    "                class_filter=cls,\n",
    "                time_range=None,\n",
    "                zscore=False,\n",
    "                threshold=cfg.get(\"threshold\"),\n",
    "                top_k=cfg.get(\"top_k\"),\n",
    "                weighted=cfg.get(\"weighted\", False),\n",
    "                absolute=cfg.get(\"absolute\", False),\n",
    "                balance=True,\n",
    "                random_state=0,\n",
    "            )\n",
    "            edge_weights = extract_edge_weights(graph, corr_matrix)\n",
    "            try:\n",
    "                communities = nx.algorithms.community.greedy_modularity_communities(graph)\n",
    "                modularity = nx.algorithms.community.modularity(graph, communities)\n",
    "            except Exception:\n",
    "                modularity = np.nan\n",
    "            strategy_result[cls] = {\n",
    "                \"corr_matrix\": corr_matrix,\n",
    "                \"corr_graph\": graph,\n",
    "                \"summary\": summary,\n",
    "                \"edge_weights\": edge_weights,\n",
    "                \"edge_weight_mean\": np.nanmean(edge_weights) if edge_weights.size else np.nan,\n",
    "                \"edge_weight_abs_mean\": np.nanmean(np.abs(edge_weights)) if edge_weights.size else np.nan,\n",
    "                \"efficiency\": summary.get(\"global_efficiency\", np.nan),\n",
    "                \"modularity\": modularity,\n",
    "            }\n",
    "        results[strategy_name] = strategy_result\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_edge_weights(graph, corr_matrix):\n",
    "    if graph.number_of_edges() == 0:\n",
    "        return np.array([], dtype=float)\n",
    "    weights = []\n",
    "    for u, v in graph.edges():\n",
    "        weights.append(float(corr_matrix[u, v]))\n",
    "    return np.asarray(weights, dtype=float)\n",
    "\n",
    "\n",
    "def aggregate_curve_dict(curve_store):\n",
    "    aggregated = {}\n",
    "    for pair, curves in curve_store.items():\n",
    "        stack = np.vstack([np.asarray(curve) for curve in curves])\n",
    "        aggregated[pair] = {\n",
    "            \"mean\": np.nanmean(stack, axis=0),\n",
    "            \"sem\": sem(stack, axis=0, nan_policy=\"omit\"),\n",
    "            \"n_mice\": stack.shape[0],\n",
    "        }\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def plot_average_fisher(curve_stats, time_points, title):\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for pair, stats_dict in sorted(curve_stats.items()):\n",
    "        label = f\"{CLASS_NAMES.get(pair[0], pair[0])} vs {CLASS_NAMES.get(pair[1], pair[1])}\"\n",
    "        mean_vals = stats_dict[\"mean\"]\n",
    "        err_vals = stats_dict[\"sem\"]\n",
    "        plt.plot(time_points, mean_vals, linewidth=2.2, label=label)\n",
    "        plt.fill_between(time_points, mean_vals - err_vals, mean_vals + err_vals, alpha=0.2)\n",
    "    plt.xlabel(\"Time (s relative to stimulus)\")\n",
    "    plt.ylabel(\"Fisher information\")\n",
    "    plt.title(title)\n",
    "    plt.axvline(0, color=\"#bbbbbb\", linestyle=\"--\", linewidth=1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def _offdiag_stats(corr_matrix):\n",
    "    if corr_matrix is None:\n",
    "        return np.nan\n",
    "    corr_matrix = np.asarray(corr_matrix)\n",
    "    if corr_matrix.ndim != 2:\n",
    "        return np.nan\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "    values = corr_matrix[mask]\n",
    "    values = values[np.isfinite(values)]\n",
    "    return values.mean() if values.size else np.nan\n",
    "\n",
    "\n",
    "def flatten_network_summary(mouse_id, strategy_name, nx_result):\n",
    "    rows = []\n",
    "    strategy_meta = GRAPH_CONFIGS.get(strategy_name, {})\n",
    "    for cls, info in nx_result.items():\n",
    "        summary = info.get(\"summary\", {}).copy()\n",
    "        row = {\n",
    "            \"mouse_id\": mouse_id,\n",
    "            \"strategy\": strategy_name,\n",
    "            \"strategy_label\": strategy_meta.get(\"label\", strategy_name),\n",
    "            \"class_label\": cls,\n",
    "            \"class_name\": CLASS_NAMES.get(cls, str(cls)),\n",
    "        }\n",
    "        for metric_name, value in summary.items():\n",
    "            row[metric_name] = value\n",
    "        row[\"efficiency\"] = info.get(\"efficiency\", np.nan)\n",
    "        row[\"modularity\"] = info.get(\"modularity\", np.nan)\n",
    "        row[\"edge_weight_mean\"] = info.get(\"edge_weight_mean\", np.nan)\n",
    "        row[\"edge_weight_abs_mean\"] = info.get(\"edge_weight_abs_mean\", np.nan)\n",
    "        row[\"mean_correlation\"] = _offdiag_stats(info.get(\"corr_matrix\"))\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def summarize_network_metrics(df, metrics):\n",
    "    summary_rows = []\n",
    "    grouped = df.groupby([\"strategy\", \"class_label\"])\n",
    "    for (strategy, cls), group in grouped:\n",
    "        entry = {\n",
    "            \"strategy\": strategy,\n",
    "            \"strategy_label\": GRAPH_CONFIGS.get(strategy, {}).get(\"label\", strategy),\n",
    "            \"class_label\": cls,\n",
    "            \"class_name\": CLASS_NAMES.get(cls, str(cls)),\n",
    "        }\n",
    "        for metric in metrics:\n",
    "            if metric not in group:\n",
    "                continue\n",
    "            entry[f\"{metric}_mean\"] = group[metric].mean()\n",
    "            entry[f\"{metric}_sem\"] = sem(group[metric], nan_policy=\"omit\")\n",
    "        summary_rows.append(entry)\n",
    "    return pd.DataFrame(summary_rows).sort_values([\"strategy\", \"class_label\"])\n",
    "\n",
    "\n",
    "def plot_network_metric_bars(df, metric, strategy=None):\n",
    "    subset = df if strategy is None else df[df[\"strategy\"] == strategy]\n",
    "    if subset.empty or metric not in subset:\n",
    "        print(f\"No data available for metric {metric} (strategy={strategy}).\")\n",
    "        return\n",
    "    pivot = subset.pivot_table(index=\"mouse_id\", columns=\"class_label\", values=metric)\n",
    "    class_order = [cls for cls in sorted(pivot.columns) if pivot[cls].notna().any()]\n",
    "    if not class_order:\n",
    "        print(f\"No class data for metric {metric} (strategy={strategy}).\")\n",
    "        return\n",
    "    means, errors, labels = [], [], []\n",
    "    colors = [CLASS_COLORS.get(cls, \"#999999\") for cls in class_order]\n",
    "    for cls in class_order:\n",
    "        col = pivot[cls].dropna()\n",
    "        if col.empty:\n",
    "            continue\n",
    "        means.append(col.mean())\n",
    "        errors.append(sem(col, nan_policy=\"omit\"))\n",
    "        labels.append(CLASS_NAMES.get(cls, str(cls)))\n",
    "    if not means:\n",
    "        print(f\"Insufficient data for metric {metric} (strategy={strategy}).\")\n",
    "        return\n",
    "    plt.figure(figsize=(6.2, 4.2))\n",
    "    plt.bar(labels, means, yerr=errors, capsize=4, color=colors)\n",
    "    strat_label = GRAPH_CONFIGS.get(strategy, {}).get(\"label\", strategy)\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "    plt.title(strat_label)\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def aggregate_accuracy_curves(records):\n",
    "    if not records:\n",
    "        return {}\n",
    "    time_axis = None\n",
    "    observed, shuffled = [], []\n",
    "    for rec in records:\n",
    "        axis = np.asarray(rec[\"time_axis\"])\n",
    "        if time_axis is None:\n",
    "            time_axis = axis\n",
    "        elif not np.allclose(time_axis, axis):\n",
    "            raise ValueError(\"Mismatched time axes across accuracy curves.\")\n",
    "        observed.append(np.asarray(rec[\"accuracies\"]))\n",
    "        shuffled.append(np.asarray(rec[\"shuffle\"]))\n",
    "    observed = np.vstack(observed)\n",
    "    shuffled = np.vstack(shuffled)\n",
    "    return {\n",
    "        \"observed\": {\n",
    "            \"time_axis\": time_axis,\n",
    "            \"mean\": np.nanmean(observed, axis=0),\n",
    "            \"sem\": sem(observed, axis=0, nan_policy=\"omit\"),\n",
    "            \"n_mice\": observed.shape[0],\n",
    "        },\n",
    "        \"shuffled\": {\n",
    "            \"time_axis\": time_axis,\n",
    "            \"mean\": np.nanmean(shuffled, axis=0),\n",
    "            \"sem\": sem(shuffled, axis=0, nan_policy=\"omit\"),\n",
    "            \"n_mice\": shuffled.shape[0],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_average_accuracy(accuracy_stats, title=\"Decoder accuracy (mean +/- SEM)\"):\n",
    "    if not accuracy_stats:\n",
    "        print(\"No accuracy curves to plot.\")\n",
    "        return\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for key, label in ((\"observed\", \"Observed\"), (\"shuffled\", \"Label-shuffled\")):\n",
    "        stats_dict = accuracy_stats.get(key)\n",
    "        if not stats_dict:\n",
    "            continue\n",
    "        color = ACCURACY_COLORS.get(key, \"#666666\")\n",
    "        time_axis = stats_dict[\"time_axis\"]\n",
    "        mean_vals = stats_dict[\"mean\"]\n",
    "        err_vals = stats_dict[\"sem\"]\n",
    "        plt.plot(time_axis, mean_vals, label=label, color=color, linewidth=2.3)\n",
    "        plt.fill_between(time_axis, mean_vals - err_vals, mean_vals + err_vals, color=color, alpha=0.18)\n",
    "    plt.axvline(0, linestyle=\"--\", color=\"#bbbbbb\", linewidth=1.0)\n",
    "    plt.xlabel(\"Time (s relative to stimulus)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def paired_ttests_over_time(records):\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    time_axis = None\n",
    "    observed, shuffled = [], []\n",
    "    for rec in records:\n",
    "        axis = np.asarray(rec[\"time_axis\"])\n",
    "        if time_axis is None:\n",
    "            time_axis = axis\n",
    "        elif not np.allclose(time_axis, axis):\n",
    "            raise ValueError(\"Mismatched time axes across accuracy curves.\")\n",
    "        observed.append(np.asarray(rec[\"accuracies\"]))\n",
    "        shuffled.append(np.asarray(rec[\"shuffle\"]))\n",
    "    observed = np.vstack(observed)\n",
    "    shuffled = np.vstack(shuffled)\n",
    "    t_stats, p_values = ttest_rel(observed, shuffled, axis=0)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"time_point\": time_axis,\n",
    "            \"t_stat\": t_stats,\n",
    "            \"p_value\": p_values,\n",
    "            \"mean_diff\": np.nanmean(observed - shuffled, axis=0),\n",
    "            \"n_mice\": observed.shape[0],\n",
    "        }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_fi_by_neuron(fi_store):\n",
    "    stats = []\n",
    "    for count in sorted(fi_store):\n",
    "        values = np.asarray(fi_store[count], dtype=float)\n",
    "        if values.size == 0:\n",
    "            continue\n",
    "        stats.append(\n",
    "            {\n",
    "                \"neuron_count\": count,\n",
    "                \"mean\": np.nanmean(values),\n",
    "                \"sem\": sem(values, nan_policy=\"omit\"),\n",
    "                \"n_mice\": values.size,\n",
    "            }\n",
    "        )\n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_fi_by_neuron(fi_stats, title=\"FI vs neuron count (mean +/- SEM)\"):\n",
    "    if not fi_stats:\n",
    "        print(\"No FI-by-neuron data available.\")\n",
    "        return\n",
    "    counts = [item[\"neuron_count\"] for item in fi_stats]\n",
    "    means = [item[\"mean\"] for item in fi_stats]\n",
    "    errors = [item[\"sem\"] for item in fi_stats]\n",
    "    plt.figure(figsize=(7, 4.2))\n",
    "    plt.errorbar(counts, means, yerr=errors, fmt=\"-o\", color=\"#2A9D8F\", capsize=4)\n",
    "    plt.xlabel(\"Number of neurons\")\n",
    "    plt.ylabel(\"Fisher information\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def extract_corr_distributions(nx_result, max_abs=0.9):\n",
    "    corr_data = {}\n",
    "    for cls, info in nx_result.items():\n",
    "        corr_matrix = np.asarray(info.get(\"corr_matrix\"))\n",
    "        if corr_matrix is None or corr_matrix.size == 0:\n",
    "            continue\n",
    "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "        values = corr_matrix[mask]\n",
    "        if max_abs is not None:\n",
    "            values = values[np.abs(values) <= max_abs]\n",
    "        corr_data[cls] = values\n",
    "    return corr_data\n",
    "\n",
    "\n",
    "def plot_multi_class_correlation_violin(corr_store):\n",
    "    if not corr_store:\n",
    "        print(\"No correlation distributions available.\")\n",
    "        return\n",
    "    class_order = [cls for cls in sorted(corr_store.keys()) if corr_store[cls].size]\n",
    "    if not class_order:\n",
    "        print(\"No correlation distributions available.\")\n",
    "        return\n",
    "    data = [corr_store[cls] for cls in class_order]\n",
    "    labels = [CLASS_NAMES.get(cls, str(cls)) for cls in class_order]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 4.5), dpi=200)\n",
    "    parts = ax.violinplot(data, positions=np.arange(len(data)), widths=0.7, showmeans=True, showmedians=True)\n",
    "\n",
    "    for idx, pc in enumerate(parts.get('bodies', [])):\n",
    "        cls = class_order[idx]\n",
    "        pc.set_facecolor(CLASS_COLORS.get(cls, \"#999999\"))\n",
    "        pc.set_alpha(0.7)\n",
    "        pc.set_edgecolor(CLASS_COLORS.get(cls, \"#999999\"))\n",
    "        pc.set_linewidth(1.2)\n",
    "\n",
    "    for part_name in ('cbars', 'cmins', 'cmaxes', 'cmedians', 'cmeans'):\n",
    "        if part_name in parts:\n",
    "            vp = parts[part_name]\n",
    "            vp.set_edgecolor('#333333')\n",
    "            vp.set_linewidth(1.0)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel('Correlation coefficient')\n",
    "    ax.set_xlabel('Stimulus type')\n",
    "    ax.axhline(0, color='#bbbbbb', linestyle='--', linewidth=0.8)\n",
    "    ax.set_title('Pairwise correlation distributions (pooled across mice)')\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def summarize_edge_strengths(edge_strength_store):\n",
    "    rows = []\n",
    "    for strategy, class_map in edge_strength_store.items():\n",
    "        strat_label = GRAPH_CONFIGS.get(strategy, {}).get(\"label\", strategy)\n",
    "        for cls, values in class_map.items():\n",
    "            arr = np.asarray(values, dtype=float)\n",
    "            arr = arr[np.isfinite(arr)]\n",
    "            if arr.size == 0:\n",
    "                continue\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"strategy\": strategy,\n",
    "                    \"strategy_label\": strat_label,\n",
    "                    \"class_label\": cls,\n",
    "                    \"class_name\": CLASS_NAMES.get(cls, str(cls)),\n",
    "                    \"mean\": np.nanmean(arr),\n",
    "                    \"sem\": sem(arr, nan_policy=\"omit\"),\n",
    "                    \"n_mice\": arr.size,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_edge_strength_summary(edge_strength_df):\n",
    "    if edge_strength_df.empty:\n",
    "        print(\"Edge strength summary is empty.\")\n",
    "        return\n",
    "    class_order = sorted(edge_strength_df[\"class_label\"].unique())\n",
    "    strategy_order = [name for name in GRAPH_CONFIGS.keys() if name in edge_strength_df[\"strategy\"].unique()]\n",
    "    width = 0.35 / max(len(strategy_order), 1)\n",
    "    x = np.arange(len(class_order))\n",
    "\n",
    "    plt.figure(figsize=(7, 4.2))\n",
    "    for idx, strategy in enumerate(strategy_order):\n",
    "        subset = edge_strength_df[edge_strength_df[\"strategy\"] == strategy]\n",
    "        means = []\n",
    "        errors = []\n",
    "        for cls in class_order:\n",
    "            row = subset[subset[\"class_label\"] == cls]\n",
    "            if row.empty:\n",
    "                means.append(np.nan)\n",
    "                errors.append(np.nan)\n",
    "            else:\n",
    "                means.append(row[\"mean\"].iloc[0])\n",
    "                errors.append(row[\"sem\"].iloc[0])\n",
    "        offsets = x - (len(strategy_order) - 1) * width / 2 + idx * width\n",
    "        color = STRATEGY_COLORS.get(strategy, None)\n",
    "        plt.bar(offsets, means, width=width, label=GRAPH_CONFIGS[strategy][\"label\"], color=color, yerr=errors, capsize=4)\n",
    "    plt.xticks(x, [CLASS_NAMES.get(cls, str(cls)) for cls in class_order])\n",
    "    plt.ylabel(\"Mean edge weight\")\n",
    "    plt.title(\"Connection strength comparison\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def paired_ttests(df, metrics):\n",
    "    records = []\n",
    "    for strategy, subset in df.groupby(\"strategy\"):\n",
    "        for metric in metrics:\n",
    "            pivot = subset.pivot_table(index=\"mouse_id\", columns=\"class_label\", values=metric)\n",
    "            for cls_a, cls_b in CLASS_PAIRS:\n",
    "                if cls_a not in pivot.columns or cls_b not in pivot.columns:\n",
    "                    continue\n",
    "                paired = pivot[[cls_a, cls_b]].dropna()\n",
    "                if paired.shape[0] < 2:\n",
    "                    continue\n",
    "                t_stat, p_value = ttest_rel(paired[cls_a], paired[cls_b])\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"strategy\": strategy,\n",
    "                        \"strategy_label\": GRAPH_CONFIGS.get(strategy, {}).get(\"label\", strategy),\n",
    "                        \"metric\": metric,\n",
    "                        \"class_a\": CLASS_NAMES.get(cls_a, str(cls_a)),\n",
    "                        \"class_b\": CLASS_NAMES.get(cls_b, str(cls_b)),\n",
    "                        \"n_mice\": paired.shape[0],\n",
    "                        \"t_stat\": float(t_stat),\n",
    "                        \"p_value\": float(p_value),\n",
    "                        \"mean_diff\": float((paired[cls_a] - paired[cls_b]).mean()),\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(records).sort_values([\"metric\", \"p_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_results = []\n",
    "failed_mice = []\n",
    "\n",
    "for mouse_id in data_path:\n",
    "    try:\n",
    "        mouse_results.append(process_mouse(mouse_id))\n",
    "    except Exception as exc:\n",
    "        print(f\"[!] Failed to process {mouse_id}: {exc}\")\n",
    "        failed_mice.append({\"mouse_id\": mouse_id, \"error\": repr(exc)})\n",
    "\n",
    "print(f\"Processed {len(mouse_results)} mice (failed: {len(failed_mice)}).\")\n",
    "failed_mice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_mv_store = defaultdict(list)\n",
    "fisher_uv_store = defaultdict(list)\n",
    "network_rows = []\n",
    "accuracy_records = []\n",
    "fi_by_neuron_store = defaultdict(list)\n",
    "corr_distribution_store = defaultdict(list)\n",
    "time_axis = None\n",
    "\n",
    "for result in mouse_results:\n",
    "    if time_axis is None:\n",
    "        time_axis = result[\"time_points\"]\n",
    "    elif not np.allclose(time_axis, result[\"time_points\"]):\n",
    "        raise ValueError(\"Mismatched FI time axes across mice.\")\n",
    "\n",
    "    for pair, curve in result[\"fisher_mv\"].items():\n",
    "        fisher_mv_store[pair].append(np.asarray(curve))\n",
    "    for pair, curve in result[\"fisher_uv\"].items():\n",
    "        fisher_uv_store[pair].append(np.asarray(curve))\n",
    "\n",
    "    network_rows.extend(flatten_network_summary(result[\"mouse_id\"], result[\"nx_result\"]))\n",
    "\n",
    "    accuracy_payload = result.get(\"accuracy_curve\")\n",
    "    if accuracy_payload:\n",
    "        accuracy_records.append(accuracy_payload)\n",
    "\n",
    "    fi_payload = result.get(\"fi_by_neuron\")\n",
    "    if fi_payload:\n",
    "        for count, value in zip(fi_payload[\"counts\"], fi_payload[\"values\"]):\n",
    "            fi_by_neuron_store[int(count)].append(float(value))\n",
    "\n",
    "    corr_payload = extract_corr_distributions(result[\"nx_result\"])\n",
    "    for cls, values in corr_payload.items():\n",
    "        if values.size:\n",
    "            corr_distribution_store[cls].append(values)\n",
    "\n",
    "print(\n",
    "    f\"Collected {len(fisher_mv_store)} Fisher pairs, \"\n",
    "    f\"{len(accuracy_records)} accuracy curves, \"\n",
    "    f\"{sum(len(v) for v in fi_by_neuron_store.values())} FI-by-neuron entries, \"\n",
    "    f\"and {len(network_rows)} network rows.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a42767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_axis is not None and fisher_mv_store:\n",
    "    fisher_mv_stats = aggregate_curve_dict(fisher_mv_store)\n",
    "    plot_average_fisher(fisher_mv_stats, time_axis, \"Multivariate Fisher information (mean +/- SEM)\")\n",
    "else:\n",
    "    print(\"Multivariate Fisher information curves are not available.\")\n",
    "\n",
    "if time_axis is not None and fisher_uv_store:\n",
    "    fisher_uv_stats = aggregate_curve_dict(fisher_uv_store)\n",
    "    plot_average_fisher(fisher_uv_stats, time_axis, \"Univariate Fisher information (mean +/- SEM)\")\n",
    "else:\n",
    "    print(\"Univariate Fisher information curves are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accuracy_records:\n",
    "    accuracy_stats = aggregate_accuracy_curves(accuracy_records)\n",
    "    plot_average_accuracy(accuracy_stats)\n",
    "else:\n",
    "    print(\"Classification accuracy curves are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e720161",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accuracy_records:\n",
    "    accuracy_ttest_df = paired_ttests_over_time(accuracy_records)\n",
    "    accuracy_ttest_df\n",
    "else:\n",
    "    accuracy_ttest_df = pd.DataFrame()\n",
    "    print(\"No decoder accuracy data for t-tests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fi_by_neuron_store:\n",
    "    fi_by_neuron_stats = aggregate_fi_by_neuron(fi_by_neuron_store)\n",
    "    plot_fi_by_neuron(fi_by_neuron_stats)\n",
    "    pd.DataFrame(fi_by_neuron_stats)\n",
    "else:\n",
    "    print(\"FI-by-neuron curves are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1397ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if corr_distribution_store:\n",
    "    plot_multi_class_correlation_violin(corr_distribution_store)\n",
    "else:\n",
    "    print(\"No correlation distributions aggregated across mice.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if edge_strength_store:\n",
    "    edge_strength_df = summarize_edge_strengths(edge_strength_store)\n",
    "    if not edge_strength_df.empty:\n",
    "        plot_edge_strength_summary(edge_strength_df)\n",
    "        edge_strength_df\n",
    "    else:\n",
    "        print(\"Edge strength summary is empty.\")\n",
    "else:\n",
    "    edge_strength_df = pd.DataFrame()\n",
    "    print(\"No edge strength data available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e73165",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_rows:\n",
    "    network_df = pd.DataFrame(network_rows)\n",
    "    network_df\n",
    "else:\n",
    "    network_df = pd.DataFrame()\n",
    "    print(\"No network metrics were collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048714a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    network_summary_df = summarize_network_metrics(network_df, NETWORK_METRICS)\n",
    "    network_summary_df\n",
    "else:\n",
    "    network_summary_df = pd.DataFrame()\n",
    "    print(\"Summary table is empty because network_df is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf910b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    strategies = network_df[\"strategy\"].dropna().unique()\n",
    "    for metric in [\"avg_clustering\", \"global_efficiency\", \"modularity\"]:\n",
    "        for strategy in strategies:\n",
    "            plot_network_metric_bars(network_df, metric, strategy=strategy)\n",
    "else:\n",
    "    print(\"Skip plotting network comparisons because network_df is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    network_ttest_df = paired_ttests(network_df, NETWORK_METRICS)\n",
    "    network_ttest_df\n",
    "else:\n",
    "    network_ttest_df = pd.DataFrame()\n",
    "    print(\"No paired t-tests computed because network_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}