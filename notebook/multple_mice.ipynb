{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, ttest_rel\n",
    "from brainnetwork import load_data, preprocess_data, preprocess_spike_data\n",
    "from brainnetwork import classify_by_timepoints, FI_by_timepoints_v2, FI_by_neuron_count\n",
    "from brainnetwork import construct_correlation_network, compute_network_metrics_by_class\n",
    "from brainnetwork.visualization import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/beegfs_hdd/data/nfs_share/users/guiyun/nishome/Micedata/\"\n",
    "data_path =  [\"M21_1107\", \"M71_1024\",\"M77_1031\",\"M78_1017\",\"M91_1017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = {1: \"Convergent\", 2: \"Divergent\", 3: \"Random\"}\n",
    "CLASS_PAIRS = [(1, 2), (1, 3), (2, 3)]\n",
    "NETWORK_METRICS = [\n",
    "    \"n_edges\",\n",
    "    \"density\",\n",
    "    \"mean_degree\",\n",
    "    \"largest_component\",\n",
    "    \"avg_clustering\",\n",
    "    \"global_efficiency\",\n",
    "    \"local_efficiency\",\n",
    "    \"transitivity\",\n",
    "    \"efficiency\",\n",
    "    \"modularity\",\n",
    "]\n",
    "\n",
    "def process_mouse(mouse_id):\n",
    "    data_dir = os.path.join(base_dir, mouse_id)\n",
    "    print(f\"Processing {mouse_id} -> {data_dir}\")\n",
    "    neuron_data, neuron_pos, start_edges, stimulus_data = load_data(data_dir)\n",
    "    segments_spi, labels_spi, neuron_pos_spi = preprocess_spike_data(\n",
    "        neuron_data,\n",
    "        neuron_pos,\n",
    "        start_edges,\n",
    "        stimulus_data,\n",
    "    )\n",
    "    neuron_data_flo, neuron_pos_flo, start_edges_flo, stimulus_data_flo = load_data(\n",
    "        data_dir,\n",
    "        data_type=\"fluorescence\",\n",
    "    )\n",
    "    segments_flo, labels_flo, neuron_pos_flo = preprocess_data(\n",
    "        neuron_data_flo,\n",
    "        neuron_pos_flo,\n",
    "        start_edges_flo,\n",
    "        stimulus_data_flo,\n",
    "    )\n",
    "    fisher_mv, time_points_fi = FI_by_timepoints_v2(\n",
    "        segments_flo,\n",
    "        labels_flo,\n",
    "        mode=\"multivariate\",\n",
    "        reduction=None,\n",
    "    )\n",
    "    fisher_uv, time_points_fi_uv = FI_by_timepoints_v2(\n",
    "        segments_flo,\n",
    "        labels_flo,\n",
    "        mode=\"univariate\",\n",
    "        reduction=\"mean\",\n",
    "    )\n",
    "    if not np.allclose(time_points_fi, time_points_fi_uv):\n",
    "        raise ValueError(\"Time axes do not match between FI variants.\")\n",
    "    nx_result = compute_network_metrics_by_class(\n",
    "        segments_spi,\n",
    "        labels_spi,\n",
    "        neuron_pos_spi,\n",
    "        do_bootstrap=False,\n",
    "    )\n",
    "    return {\n",
    "        \"mouse_id\": mouse_id,\n",
    "        \"fisher_mv\": fisher_mv,\n",
    "        \"fisher_uv\": fisher_uv,\n",
    "        \"time_points\": time_points_fi,\n",
    "        \"nx_result\": nx_result,\n",
    "    }\n",
    "\n",
    "\n",
    "def aggregate_curve_dict(curve_store):\n",
    "    aggregated = {}\n",
    "    for pair, curves in curve_store.items():\n",
    "        stack = np.vstack([np.asarray(curve) for curve in curves])\n",
    "        aggregated[pair] = {\n",
    "            \"mean\": np.nanmean(stack, axis=0),\n",
    "            \"sem\": sem(stack, axis=0, nan_policy=\"omit\"),\n",
    "            \"n_mice\": stack.shape[0],\n",
    "        }\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def plot_average_fisher(curve_stats, time_points, title):\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for pair, stats_dict in sorted(curve_stats.items()):\n",
    "        label = f\"{CLASS_NAMES.get(pair[0], pair[0])} vs {CLASS_NAMES.get(pair[1], pair[1])}\"\n",
    "        mean_vals = stats_dict[\"mean\"]\n",
    "        err_vals = stats_dict[\"sem\"]\n",
    "        plt.plot(time_points, mean_vals, linewidth=2.2, label=label)\n",
    "        plt.fill_between(time_points, mean_vals - err_vals, mean_vals + err_vals, alpha=0.2)\n",
    "    plt.xlabel(\"Time (s relative to stimulus)\")\n",
    "    plt.ylabel(\"Fisher information\")\n",
    "    plt.title(title)\n",
    "    plt.axvline(0, color=\"#bbbbbb\", linestyle=\"--\", linewidth=1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def flatten_network_summary(mouse_id, nx_result):\n",
    "    rows = []\n",
    "    for cls, info in nx_result.items():\n",
    "        summary = info.get(\"summary\", {}).copy()\n",
    "        row = {\n",
    "            \"mouse_id\": mouse_id,\n",
    "            \"class_label\": cls,\n",
    "            \"class_name\": CLASS_NAMES.get(cls, str(cls)),\n",
    "        }\n",
    "        for metric_name, value in summary.items():\n",
    "            row[metric_name] = value\n",
    "        row[\"efficiency\"] = info.get(\"efficiency\", np.nan)\n",
    "        row[\"modularity\"] = info.get(\"modularity\", np.nan)\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def summarize_network_metrics(df, metrics):\n",
    "    summary_rows = []\n",
    "    for cls, group in df.groupby(\"class_label\"):\n",
    "        entry = {\n",
    "            \"class_label\": cls,\n",
    "            \"class_name\": CLASS_NAMES.get(cls, str(cls)),\n",
    "        }\n",
    "        for metric in metrics:\n",
    "            entry[f\"{metric}_mean\"] = group[metric].mean()\n",
    "            entry[f\"{metric}_sem\"] = sem(group[metric], nan_policy=\"omit\")\n",
    "        summary_rows.append(entry)\n",
    "    return pd.DataFrame(summary_rows).sort_values(\"class_label\")\n",
    "\n",
    "\n",
    "def plot_network_metric_bars(df, metric):\n",
    "    pivot = df.pivot_table(index=\"mouse_id\", columns=\"class_label\", values=metric)\n",
    "    class_order = [cls for cls in sorted(pivot.columns) if pivot[cls].notna().any()]\n",
    "    means, errors, labels = [], [], []\n",
    "    colors = [\"#1F77B4\", \"#D55E00\", \"#009E73\", \"#9467BD\"]\n",
    "    for cls in class_order:\n",
    "        col = pivot[cls].dropna()\n",
    "        if col.empty:\n",
    "            continue\n",
    "        means.append(col.mean())\n",
    "        errors.append(sem(col, nan_policy=\"omit\"))\n",
    "        labels.append(CLASS_NAMES.get(cls, str(cls)))\n",
    "    plt.figure(figsize=(6.2, 4.2))\n",
    "    plt.bar(labels, means, yerr=errors, capsize=4, color=colors[: len(labels)])\n",
    "    plt.ylabel(metric.replace(\"_\", \" \").title())\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def paired_ttests(df, metrics, class_pairs=CLASS_PAIRS):\n",
    "    records = []\n",
    "    for metric in metrics:\n",
    "        pivot = df.pivot_table(index=\"mouse_id\", columns=\"class_label\", values=metric)\n",
    "        for cls_a, cls_b in class_pairs:\n",
    "            if cls_a not in pivot.columns or cls_b not in pivot.columns:\n",
    "                continue\n",
    "            paired = pivot[[cls_a, cls_b]].dropna()\n",
    "            if paired.shape[0] < 2:\n",
    "                continue\n",
    "            t_stat, p_value = ttest_rel(paired[cls_a], paired[cls_b])\n",
    "            records.append(\n",
    "                {\n",
    "                    \"metric\": metric,\n",
    "                    \"class_a\": CLASS_NAMES.get(cls_a, str(cls_a)),\n",
    "                    \"class_b\": CLASS_NAMES.get(cls_b, str(cls_b)),\n",
    "                    \"n_mice\": paired.shape[0],\n",
    "                    \"t_stat\": float(t_stat),\n",
    "                    \"p_value\": float(p_value),\n",
    "                    \"mean_diff\": float((paired[cls_a] - paired[cls_b]).mean()),\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(records).sort_values(\"p_value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_results = []\n",
    "failed_mice = []\n",
    "\n",
    "for mouse_id in data_path:\n",
    "    try:\n",
    "        mouse_results.append(process_mouse(mouse_id))\n",
    "    except Exception as exc:\n",
    "        print(f\"[!] Failed to process {mouse_id}: {exc}\")\n",
    "        failed_mice.append({\"mouse_id\": mouse_id, \"error\": repr(exc)})\n",
    "\n",
    "print(f\"Processed {len(mouse_results)} mice (failed: {len(failed_mice)}).\")\n",
    "failed_mice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_mv_store = defaultdict(list)\n",
    "fisher_uv_store = defaultdict(list)\n",
    "network_rows = []\n",
    "time_axis = None\n",
    "\n",
    "for result in mouse_results:\n",
    "    if time_axis is None:\n",
    "        time_axis = result[\"time_points\"]\n",
    "    elif not np.allclose(time_axis, result[\"time_points\"]):\n",
    "        raise ValueError(\"Mismatched FI time axes across mice.\")\n",
    "    for pair, curve in result[\"fisher_mv\"].items():\n",
    "        fisher_mv_store[pair].append(np.asarray(curve))\n",
    "    for pair, curve in result[\"fisher_uv\"].items():\n",
    "        fisher_uv_store[pair].append(np.asarray(curve))\n",
    "    network_rows.extend(flatten_network_summary(result[\"mouse_id\"], result[\"nx_result\"]))\n",
    "\n",
    "print(f\"Collected {len(fisher_mv_store)} Fisher curve pairs and {len(network_rows)} network entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a42767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_axis is not None and fisher_mv_store:\n",
    "    fisher_mv_stats = aggregate_curve_dict(fisher_mv_store)\n",
    "    plot_average_fisher(fisher_mv_stats, time_axis, \"Multivariate Fisher information (mean ? SEM)\")\n",
    "else:\n",
    "    print(\"Multivariate Fisher information curves are not available.\")\n",
    "\n",
    "if time_axis is not None and fisher_uv_store:\n",
    "    fisher_uv_stats = aggregate_curve_dict(fisher_uv_store)\n",
    "    plot_average_fisher(fisher_uv_stats, time_axis, \"Univariate Fisher information (mean ? SEM)\")\n",
    "else:\n",
    "    print(\"Univariate Fisher information curves are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e73165",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_rows:\n",
    "    network_df = pd.DataFrame(network_rows)\n",
    "    network_df\n",
    "else:\n",
    "    network_df = pd.DataFrame()\n",
    "    print(\"No network metrics were collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048714a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    network_summary_df = summarize_network_metrics(network_df, NETWORK_METRICS)\n",
    "    network_summary_df\n",
    "else:\n",
    "    network_summary_df = pd.DataFrame()\n",
    "    print(\"Summary table is empty because network_df is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf910b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    for metric in [\"avg_clustering\", \"global_efficiency\", \"modularity\"]:\n",
    "        plot_network_metric_bars(network_df, metric)\n",
    "else:\n",
    "    print(\"Skip plotting network comparisons because network_df is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not network_df.empty:\n",
    "    network_ttest_df = paired_ttests(network_df, NETWORK_METRICS)\n",
    "    network_ttest_df\n",
    "else:\n",
    "    network_ttest_df = pd.DataFrame()\n",
    "    print(\"No paired t-tests computed because network_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
